---
title: "ILSA and Digital Self-efficacy"
author: "Tomás Urzúa"
format:
  html: 
    echo: false
    warning: false

header-includes: |
    <img src="../input/jpg/nudos_bajada.jpg" style="width: 100%;" class="header-image" />
editor: visual
bibliography:
  - bib/ilsa_part.bib 
  - bib/digcomp.bib
csl: bib/apa.csl 
css: libs/nudos.css
---

## About ICILS, TIMSS and PISA

Within the ILSAs, there are two major organizations that have promoted this type of study: the IEA and the OECD. On the one hand, the IEA is the association in charge of leading and conducting two of the most important large-scale assessment studies: International Computer and Information Literacy Study (ICILS) and Trends in International Mathematics and Science Study (TIMSS). On the other hand, the OECD is the orchestrator of the Programme for International Student Assessment (PISA), one of the world's leading ILSAs. These three studies share the same target population in that they focus on adolescents, specifically 13-15 year olds. Fundamentally, all of the aforementioned studies contain a digital self-efficacy battery, so the following paragraphs will attempt to describe at a general level each of the ILSAs and then show how they address digital self-efficacy in their evaluative frameworks. Subsequently, a comparative analysis will be made between the digital self-efficacy batteries between cycles of the same study, as well as between different studies, to finally propose a discussion on the successes and failures in the different measurements that have been proposed with respect to digital self-efficacy.

### ICILS

ICILS is a study on digital literacy, which seeks to answer the question: How well are students prepared to study, work and live in a digital world? To this end, the study measures achievement in computer and information literacy (CIL), a concept defined as “an individual's ability to use computers to investigate, create, and communicate in order to participate effectively at home, at school, in the workplace, and in society” [@julianfraillon_iea_2013, p. 17]. It is worth mentioning that this concept is operationalized by ICILS in order to measure digital literacy. The study deploys a complex sample design involving multistage, stratified and cluster sampling techniques [see p.59, @julianfraillon_sample_2020].

The first ICILS study cycle was conducted in 2013. It involved 22 educational systems, and was the inaugural milestone of the study that seeks to measure achievement in CIL ([see on official website](https://www.iea.nl/studies/iea/icils)). Subsequently, the second cycle of the study occupied 2018, covering only 13 countries, but Computational Thinking domain was added as one of the key aspects to be studied. Recently, the report of the results of the third cycle of the 2023 study was published, in addition to the release of the databases for free use by the community.

As mentioned above, ICILS is a study that is framed within the digital theme, so all its sections focus on one aspect of it. In this context, the evaluation framework of this study contains a chapter focused on contextual determinants, which is subdivided into the types of context that influence computer and information literacy, such as the family context, the school context and the individual context. The latter includes attitudinal and behavioral factors. Self-efficacy is placed in this framework.

To conceptualize self-efficacy, the study paraphrases Bandura's (1993) definition, stating that self-efficacy is students' confidence in their own ability to perform tasks in a specific area [Bandura, 1993, cited in @julianfraillon_iea_2013]. Thus, it is made explicit that the questionnaire aims to measure the confidence expressed by students when performing ICT-related tasks. In this sense, ICILS employs the concept of ICT self-efficacy. In addition, mention is made of the previous wave of the study, highlighting the identification of two dimensions of self-efficacy: basic and advanced. This distinction is continued in this study. Finally, literature is presented that supports the idea that self-efficacy is a relevant variable for predicting performance, in this case, in computational and information literacy [see p. 41, @fraillon_contextual_2019].

### TIMSS

The second study to be analyzed in this paper is TIMSS, which is conducted by the IEA and PIRLS International Study Center at Boston College's Lynch School of Education and Human Development. This ILSA, as its name implies, focuses on assessing the performance of fourth and eighth grade students in mathematics and science. In addition, it contains questions related to the students' context.

The first TIMSS study was carried out in 1995 and has been conducted periodically every 4 years without fail. Regarding the most recent cycles, it is worth mentioning that TIMMS 2019 was attended by 72 educational systems, while the subsequent cycle carried out in 2023 repeated the same number of participants ([see on official website](https://www.iea.nl/studies/iea/timss)). The results of the eighth and final cycle of the study have recently been published, and the next cycle, which is scheduled for 2027, is already in sight. It is important to mention that the sample design of this study is based on a two-stage stratified random sampling, with the sample of schools as the first stage and the selection of the classes of students in each school as the second stage [see p. 3.1, @siegelp._timss_2024].

Regarding the approach to technology in their questionnaires, in the 2011 cycle we found for the first time the presence of questions on this topic, although they only referred to the frequency of computer use at home and at school.

TIMMS is the study with the least extensive assessment framework on digital issues, so it can be assumed that it is not a section that has been given priority in the questionnaire. Instead, information on student performance in mathematics and science prevails.

Regarding digital self-efficacy, the TIMMS cycle conducted in 2019 conceptualizes self-efficacy as “Students‘ confidence in using technology,” found in the section “Students’ attitudes toward learning,” where students' attitudes toward mathematics and science are also highlighted [see pp. 72, @inav.s.mulllis_timss_2019]. Later, in the 2023 cycle of the same study, the concept changes to “digital self-efficacy”, which is framed under “Information technologies and digital services”. In it, two variables are specified: uses of digital services (1) and digital self-efficacy (2). In neither of the two cycles is there a previous contextualization that supports the presentation of these topics, nor a deep justification of why self-efficacy in digital issues is relevant. Nor is there a conceptualization of self-efficacy as such. Despite all these gaps, the study does employ a specific concept in its two cycles [see p. 59, @inav.s.mulllis_timss_2023]. 

Despite the lack of theoretical depth regarding digital self-efficacy, one of the most interesting features of TIMMS is that, in addition to containing the digital self-efficacy battery, it has self-efficacy batteries for mathematics and science, which could open certain lines of research regarding this specific topic.

### PISA

Finally, there is PISA, a study that is organized and executed by the OECD. PISA is characterized by measuring the abilities of 15-year-old adolescents to use their knowledge in reading, mathematics and science to face challenges in real life. This ILSA stands out for the great thematic versatility of its questionnaires. For example, the 2022 cycle contained 7 surveys, which dealt with topics such as financial literacy or good living. In addition, in each cycle of the study, one domain area takes center stage. Particularly, in 2018, the area of reading predominated, while the 2022 study focused especially on the mathematical area.

PISA originated in 2000, and since that year the study has been carried out periodically every 3 years. The only cycles that escape this rule are those of 2022 and 2025 (next to be carried out), since the pandemic and the subsequent cancellation of face-to-face classes prevented the surveys from being duly deployed in 2021. For this reason, the eighth cycle of PISA (2021 initially) was postponed to the following year, consequently affecting the date of the subsequent cycle. A noteworthy aspect is that since the first PISA cycle, space has been given to familiarity with technology.

This study implements a two-stage stratified sample design. The first stage were schools that had 15-year-old students to be surveyed, as the second sampling units were the students within sampled schools [see p. 104, @oecd_pisa_2024]. In terms of participation levels in the latest studies, the cycle conducted in 2018 had 79 countries and economies, while the study conducted in 2022 was made up of 81 participants. Both cycles included OECD and non-OECD members.

A striking aspect of PISA is that from the beginning of the study they have contemplated a questionnaire on familiarity with technology. Due to rapid technological transformations, this questionnaire has undergone constant modifications. Nevertheless, digital self-efficacy appears as an inconsistent item in the different PISA cycles. In both 2000 and 2009 digital self-efficacy is absent in the questionnaires, however, in all other cycles it is present.

On the other hand, PISA has an ICT assessment framework, which considers 3 dimensions: ICT Uses; ICT Access and ICT Competencies of students. The latter specifies the most relevant competencies identified in the existing assessment frameworks on digital literacy. It should be noted that the framework provided by PISA goes in the direction of laying the foundations for, in the future, being able to integrate ICT literacy as a specific domain in its study. Thus, the document defines ICT literacy as “the interest, attitude and ability of individuals to use digital technologies and communication tools appropriately to access, manage, integrate and evaluate information, construct new knowledge and communicate with others in order to participate effectively in society” [Lenon et al., 2003, cited in @oecd_pisa_2023]. This definition is not original to PISA, but draws on the conceptualization of Lenon et al. (2003).

ICT competencies include knowledge, understanding, attitudes, dispositions and skills. Self-efficacy is found among attitudes and dispositions towards ICT. In greater depth, the 5 main areas of ICT competencies are: accessing, managing and evaluating information and data (1); sharing information and communicating (2); transforming and creating digital content (3); individual and collaborative problem solving in digital contexts, and computational thinking (4); appropriate use of ICT (knowledge and skills related to safety, security and risk awareness) (5). In this context, it is made explicit that the measure of self-efficacy is the main instrument for assessing ICT competencies.

It is worth mentioning that PISA does not explicitly define “digital self-efficacy”, but treats self-efficacy throughout the document in the framework of attitudes and dispositions towards ICT, so there is no specific concept of self-efficacy [see p. 277, @oecd_pisa_2023].

### Advantages and disadvantages of each study

First of all, ICILS has a large number of variables that are framed within the digital theme, which is of great value taking into account the purpose of this paper. In this sense, ICILS allows innumerable models using these variables to understand how and to what extent they are related to digital self-efficacy. 

Another strength of ICILS is that it presents two types of digital self-efficacy, differentiating it from TIMSS and PISA, since these two only consider a general dimension of digital self-efficacy. From this, ICILS opens the possibility of, firstly, being able to distinguish not only theoretically but empirically two types of self-efficacy, and secondly, it allows us to account for the implications that self-efficacy can have in society, whether general or specialized. 

On the other hand, TIMSS is not framed in digital issues, which is demonstrated by the lack of extension and rigor in the treatment of digital self-efficacy in its documents. Although they present a specific concept that allows the reader to get an idea of what they are talking about, they do not provide greater clarity to understand the concept. 

However, an extremely valuable aspect of TIMSS is that it has self-efficacy batteries in its core subjects, mathematics and science. This opens up the possibility of investigating a possible relationship between different types of self-efficacy, which would be important to consider for future projects. 

PISA has a particular characteristic, which is the approach to digital self-efficacy from its first cycles. Although there are some cycles that do not handle this battery, it would still be possible to study how digital self-efficacy has been measured since the beginning of this study and to what extent its measurement has changed over the years.

One of the shortcomings of PISA is the lack of a concept for digital self-efficacy. Both ICILS and TIMSS propose a definition of this concept (ICT self-efficacy and Digital self-efficacy, respectively), but PISA leaves the concept to the reader's interpretation. However, this is somewhat compensated for by the completeness of the theoretical framework on digital issues. 
As a general aspect to highlight, each study has extensive documentation that is freely accessible, which can be found on their respective web pages. There, the questionnaires applied, technical reports and databases, among other files, can be consulted and downloaded. The openness of their data is of great value, as it allows them to be analyzed to generate knowledge in various fields, such as academia or public policy.

Finally, it is extremely important to clarify that both TIMMS and PISA use characterization questionnaires as the only resource to address digital issues, which, ultimately, does not allow measuring the competencies or skills of respondents. ICILS does not, which, in addition to covering characterization elements, deploys a standardized performance assessment test, the objective of which is that digital literacy can be measured in a concrete way.

## Measures of digital self-efficacy

Table 3 shows the digital self-efficacy batteries belonging to the last two cycles of each study mentioned above, including some of their characteristics such as item phrasing and/or response categories. This was done in order to illustrate the differences that exist between the different cycles of a study, as well as the differences between studies.

```{r}
library(kableExtra)
library(openxlsx)

table <- openxlsx::read.xlsx("input/tbl/self-eff_comparison_bateries.xlsx", fillMergedCells = TRUE)
table[is.na(table)] <- ""

table |>
  knitr::kable() |>
scroll_box(height="800px")
```


Firstly, in ICILS, it can be observed that the specific concept with which they deal with digital self-efficacy has been maintained, using “ICT Self-efficacy” in its two cycles. Likewise, both the item phrasing and the response categories that were proposed in the first cycle of the study remained unchanged in the second cycle.

On the contrary, the change in the conceptualization of the type of ICT self-efficacy dimensions stands out, since, while in the 2013 cycle they were defined as “basic and advanced”, in the 2018 cycle this was modified to “general and specialized”. Now, the most significant change is in the items that make up the ICT Self-efficacy batteries in the two cycles. In the basic-general dimension, for the 2013 cycle there are 6 items, finding a tendency towards digital editing and searching tasks, while in the 2018 cycle there are 8 items in total, including topics of program installation and information evaluation. On the other hand, in the advanced-specialized dimension there is a decrease of items when comparing the first and second cycle. In 2013 this battery was made up of 7 items, and in 2018 only 4, leaving aside tasks such as removing viruses from a computer or using spreadsheets.

The digital-themed self-efficacy batteries in PISA change almost all of their characteristics from one cycle to the next, only keeping the understanding of self-efficacy on a single dimension. First, the item phrasing in the 2018 cycle attends to the extent to which the respondent agrees or disagrees with the statements to be presented. In contrast, in the 2022 cycle it refers to the extent to which the respondent is able to perform the tasks that will be presented. These changes in the phrasing of the item also have implications for the response categories of the cycles, since they point to different questions. For the 2018 cycle the responses are based on a scale ranging from “strongly disagree” to “strongly agree,” while the response categories for the last cycle range from “I cannot do it” to “I can do it easily.”

The items of the PISA batteries also underwent several changes. First, the 2022 cycle has 3 more items compared to the 2018 cycle. To elaborate on this, the items of the first cycle of this study are mainly made up of statements that allude to the feeling of comfort with the use of digital services, as well as tasks that point to autonomy in the digital sphere. In contrast, the 2022 items focus on task performance, including skills ranging from practical knowledge to critical evaluation. In addition, it can be generally noted that the battery is constructed in such a way that the first items point to tasks that do not demand great complexity, while the last items require much more in-depth knowledge and skills in the digital domain.

The measurement of digital self-efficacy in TIMSS has maintained certain characteristics, specifically the consideration of a single self-efficacy dimension, item phrasing and subsequent response categories. The question that supports this battery expresses the degree to which one agrees with the statements, so the response categories range from “strongly agree” to “strongly disagree”.

Now, the concept with which self-efficacy in digital subjects is treated is different between the two TIMMS cycles. For the 2019 cycle the concept “Student confidence using techonology” was used, which in the 2023 cycle would change to “Digital Self-efficacy”.

Another aspect that underwent modifications was the construction of the digital self-efficacy batteries. In the previous cycle, the battery consisted of 7 items, which focused on practical tasks of a low level of complexity; among them, “being good at typing” or “being able to use a touchscreen”. In TIMSS 2023, the same number of items are observed, but they address tasks that require greater knowledge in the field, such as creating presentations or graphics, or feeling able to help others in the use of digital services.

Between ICILS, PISA and TIMSS, major differences can be noted in terms of the characteristics of their self-efficacy batteries in the digital domain. First, TIMSS is the only study that has modified the conceptualization of self-efficacy in relation to technology. However, ICILS stands out for comprising two dimensions of digital self-efficacy, whereas the other studies only take into account one generalized dimension. On the other hand, the item phrasings and the response categories derived from them differ between each study. The closest studies in these measurement characteristics are PISA 2018 with the two TIMMS cycles when measuring the degree of agreement.

The greatest differences are found in the items that make up the digital self-efficacy batteries. Each study has undergone transformations in the items that make up the batteries, some including a greater number of statements, or adding tasks of greater complexity and omitting aspects that were measured in their respective previous cycles.

This section conducted a comparative analysis of the construction of the digital self-efficacy batteries, observing the items that constitute such batteries in the different cycles of the different studies, as well as the differences presented intra-cycle and intra-study. The next section seeks to deepen the analysis of how self-efficacy in digital issues has been measured in the studies presented in the document, through an evaluation based on the conceptual framework provided by Bandura, which was presented in the first part of this working paper.