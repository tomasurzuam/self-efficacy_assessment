---
title: "DigComp analysis"
author: "Tomás Urzúa"
format:
  html: 
    echo: false
    warning: false

header-includes: |
    <img src="../input/jpg/nudos_bajada.jpg" style="width: 100%;" class="header-image" />
editor: visual
bibliography:
  - bib/ilsa_part.bib 
  - bib/digcomp.bib
csl: bib/apa.csl 
css: libs/nudos.css
---

## DigComp

The European Commission recognizes eight key skills that citizens must acquire to enable them to actively participate in society, among which are digital competencies. This is based on the growing presence of technology in human life, which has given rise to problems such as the digital divide. In this regard, the European Commission considers that digital inclusion currently depends more on knowledge, skills and attitudes than on access and use [@erstad_educating_2010]. 

Due to the need to promote digital inclusion, the DigComp is created [@ferrari_digcomp_2013], proposing a framework of competencies to perform adequately in the aforementioned area. Five areas of competence are presented: information, communication, creation, security and problem solving. Subsequently, each of these competency areas is dissected into specific competencies. In addition, three levels of proficiency are presented for each competency area: foundation, intermediate and advanced. 

Now, since its creation in 2013, new iterations have emerged that have sought to improve the initial DigComp framework. The first iteration is called DigComp 2.0 [@vuorikari_digcomp_2016]. In it, some vocabulary issues are clarified with respect to the first study, especially by relieving the “digital” character in most competencies. For example, the area “information” becomes “information and data literacy”, or “content creation” is modified to “digital content creation”. These decisions are justified in the document due to the increasing pace of transformation in the digital world. In addition, the description of specific competencies is updated. 

Subsequently, DigComp 2.1 is presented [@carretero_digcomp_2017]. In this second iteration, they increase the levels of mastery from 3 to 8. This broadening and deepening of such levels is done with the idea of helping the design of assessment tools for the development of citizens' competencies. The 8 levels of mastery are based on Bloom's taxonomy and the vocabulary of the European Qualification Framework (EQF). The 8 levels of mastery are categorized by each specific competency, so that there are a total of 168 descriptors. In addition, the examples of each competency in the educational and work environment are updated. With this, the framework offered by the DigComp becomes much more complex with respect to previous editions, proposing a rigorous design but at the same time understandable thanks to a clear and well-structured design. 

Finally, this is the third iteration and the most updated version of the digital competencies framework called DigComp 2.2 [@vuorikari_digcomp_2022]. This document uses the same framework proposed in the previous version, but in addition each descriptor has examples based on the fourth dimension (knowledge, skills and attitudes). In addition, there is the novelty of including artificial intelligence topics.

## DigComp and Digital Self-efficacy Assessment

Based on the latest update of the DigComp, the following table will be analyzed, which is composed of the digital self-efficacy batteries used by ICILS, PISA and TIMSS in their last two cycles, respectively. 

```{r}
library(kableExtra)
library(openxlsx)

table <- openxlsx::read.xlsx("input/tbl/digcomp_tbl.xlsx", fillMergedCells = TRUE)
table[is.na(table)] <- ""

table |>
  knitr::kable() |>
scroll_box(height="800px")
```

As can be seen, in the two cycles of ICILS most of its items are concentrated in the areas of information and data literacy and digital content creation. It could be said that ICILS regresses in the coverage of competency areas, since in the 2013 cycle at least two items were assigned to the Problem Solving area, but in its subsequent cycle they forget about it, while both Communication and Collaboration and Safety were not considered at all. 

Moving on to PISA, in the first cycle of this study it is observed that the items mostly occupy the areas of information and data literacy and problem solving. Although there is one item in Communication and Collaboration, the disproportion of the items in the other areas is evident. However, in the second cycle there is evidence of a transformation in the construction of the items, which ends up resolving to a large extent the shortcoming of the 2018 cycle, as each competency area is covered in the PISA 2022 digital self-efficacy battery. 

In the first TIMSS cycle, on the other hand, almost all of the items cover only the area of information and data literacy, while the remaining one is located in digital content creation, a pattern shared with ICILS. For the 2023 cycle it is almost the same scenario, which is demonstrated by the fact that the items occupy the two areas already mentioned above, and there is only one item that is framed in Problem Solving. 

From the above analysis, it can be stated that both ICILS and TIMSS have built their self-efficacy batteries focusing on literacy issues and digital content creation, but notably lack items that consider communication and collaboration, safety, and problem solving. 

PISA is the study that has put the most effort into extending the measurement of digital self-efficacy to the other skill areas, reflected in the change in batteries between its two cycles. Even so, areas such as Safety were barely considered with only one item, and Problem Solving with two.

It is unknown whether these three ILSAs have used the DigComp framework to construct their digital self-efficacy batteries, but it is clear that it is a pending task to rethink both the theoretical and empirical bases to which these studies resort for the formulation of these items, in order to sophisticate and, in sum, improve the measurement of digital self-efficacy. 

## Recommendations 

The digital self-efficacy battery created by Ulfert-Blank & Schmidt (2022) is the ideal example for assessing this construct, since it offers one item for each subcompetency that is part of the competency areas, accounting for a total of 21 items. Using this battery as a model for the formulation of subsequent digital self-efficacy batteries would be completely fruitful for the ILSA field, since so far the existing batteries are not even able to cover all competency areas in a balanced way.